{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/igorafaelms/rsna_handson/blob/master/RSNA_for_Non_Coders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uH4B_VCqjKy3"
   },
   "source": [
    "<center> <img src=\"https://www.rsna.org/-/media/Images/RSNA/Annual-meeting/RSNA2019_BrandedLogo.ashx?w=300&hash=B0A0C4C31EBDB8863C61F3EBD84EA6EF84759AE9&la=en\"> </center>\n",
    "<a style=\"background-color:black;color:white;text-decoration:none;padding:4px 6px;font-family:-apple-system, BlinkMacSystemFont, &quot;San Francisco&quot;, &quot;Helvetica Neue&quot;, Helvetica, Ubuntu, Roboto, Noto, &quot;Segoe UI&quot;, Arial, sans-serif;font-size:12px;font-weight:bold;line-height:1.2;display:inline-block;border-radius:3px\" href=\"https://unsplash.com/@cdc?utm_medium=referral&amp;utm_campaign=photographer-credit&amp;utm_content=creditBadge\" target=\"_blank\" rel=\"noopener noreferrer\" title=\"Download free do whatever you want high-resolution photos from CDC\"><span style=\"display:inline-block;padding:2px 3px\"><svg xmlns=\"http://www.w3.org/2000/svg\" style=\"height:12px;width:auto;position:relative;vertical-align:middle;top:-2px;fill:white\" viewBox=\"0 0 32 32\"><title>unsplash-logo</title><path d=\"M10 9V0h12v9H10zm12 5h10v18H0V14h10v9h12v-9z\"></path></svg></span><span style=\"display:inline-block;padding:2px 3px\">CDC</span></a>\n",
    "\n",
    "# RSNA 2019 Annual Meeting\n",
    "\n",
    "# Hands-on - Deep Learning for Intracranial Hemorrhage Detection\n",
    "\n",
    "\n",
    "\n",
    "**Developed by:**\n",
    "\n",
    "Luciano M. Prevedello, MD, MPH (luciano.prevedello@osumc.edu)\n",
    "\n",
    "Felipe Campos Kitamura, MD, MSc (kitamura.felipe@gmail.com)\n",
    "\n",
    "Igor Santos, MD (igor.msantos@fidi.org.br)\n",
    "\n",
    "Ian Pan (ianpan358@gmail.com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbAUq1KmksS9"
   },
   "source": [
    "**Step by step:**\n",
    "\n",
    "All the process will be demonstrated with Python 3 running on Google Colaboratory. Please make sure you have GPU enabled under notebook settings before you proceed.\n",
    "\n",
    "**There are 3 training sets:**\n",
    "\n",
    "- Dataset 0 comprises 60 normal and 6 hemorrhage head CT images.\n",
    "\n",
    "- Dataset 1 comprises 33 normal and 33 hemorrhage head CT images.\n",
    "\n",
    "- Dataset 2 comprises 60 normal and 60 hemorrhage head CT images.\n",
    "\n",
    "Validation and Test sets have 20 normal and 20 hemorrhage each, except for dataset 0 (20 normal and 2 hemorrhages).\n",
    "\n",
    "For each specific task we will import specific libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WwFwbMGIuHsH"
   },
   "source": [
    "## **<center> Python Libraries </center>**\n",
    "<center> <img src=\"https://github.com/igorafaelms/rsna_handson/blob/master/libraries.png?raw=true\"> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_hkRJ8W-6xF"
   },
   "outputs": [],
   "source": [
    "#@title System Setup - After installation the the system will restart. This will generate an error message which is expected. Just ignore it :) {display-mode: \"form\"}\n",
    "#Installing dependencies\n",
    "\n",
    "import sys, os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "default_stdout = sys.stdout\n",
    "file_handle = open(os.devnull, \"w\")\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "sys.stdout = file_handle\n",
    "\n",
    "!pip3 install keras-vis\n",
    "!pip3 install imgaug==0.2.5\n",
    "!pip3 install scipy==1.2.1\n",
    "!pip3 install graphviz\n",
    "!pip uninstall matplotlib --yes\n",
    "!pip install matplotlib==3.1.0\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u9dmrWVwRbDR"
   },
   "outputs": [],
   "source": [
    "#@title Dataset Download {display-mode: \"form\"}\n",
    "\n",
    "import sys, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "default_stdout = sys.stdout\n",
    "file_handle = open(os.devnull, \"w\")\n",
    "sys.stderr = open(os.devnull, \"w\")\n",
    "\n",
    "sys.stdout = file_handle\n",
    "\n",
    "#@title\n",
    "#First of all, we are going to download the zip files with the images to this instance of Google's Colaboratory\n",
    "\n",
    "!wget https://github.com/kitamura-felipe/deeplearning_head_ct_demo/blob/master/Allcases.zip?raw=true \n",
    "!wget https://github.com/kitamura-felipe/deeplearning_head_ct_demo/blob/master/33_33.zip?raw=true\n",
    "!wget https://github.com/kitamura-felipe/deeplearning_head_ct_demo/blob/master/60_6.zip?raw=true\n",
    "  \n",
    "  #@title\n",
    "#Let's unzip them\n",
    "\n",
    "\n",
    "\n",
    "!unzip -o Allcases.zip?raw=true -d /Cases\n",
    "!unzip -o 33_33.zip?raw=true -d /Cases\n",
    "!unzip -o 60_6.zip?raw=true -d /Cases\n",
    "\n",
    "sys.stdout.write('foo bar')\n",
    "\n",
    "sys.stdout = default_stdout\n",
    "sys.stderr = sys.__stderr__  \n",
    "\n",
    "print ('\\033[1m' + 'All images dowloaded. Please check folder contents under \"Files\" on the left!')\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://github.com/lprevedello/RSNA-2019-Hands-on/blob/master/folders.png?raw=true\", width=900, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrsQG6zJHI5F"
   },
   "outputs": [],
   "source": [
    "#@title Dataset Selection and Preprocessing {display-mode: \"form\"}\n",
    "\n",
    "Dataset = \"60/60\" #@param [\"60/6\", \"33/33\", \"60/60\"]\n",
    "Augmentation = \"on\" #@param [\"off\", \"on\", \"custom\"]\n",
    "angle = 18 #@param {type:\"slider\", min:0, max:359, step:1}\n",
    "zoom = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "width_shift_range = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "height_shift_range = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "shear_range = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "horizontal_flip = True #@param {type:\"boolean\"}\n",
    "\n",
    "# Importing libraries for arrays (NumPy), Pre-processing (Keras) and plotting images (Matplotlib)\n",
    "%tensorflow_version 1.x\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "# It is important to set a random seed in order to have reproducbility of training results between different users\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(123)\n",
    "\n",
    "# Dimensions which our images will be resized for the input. All of them must have the same size\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# We split the data between 60/10/30% for training/validation/test sets \n",
    "# We choose which directories must be used\n",
    "\n",
    "validation_data_dir = '/Cases/All cases/Validation/'\n",
    "nb_validation_samples = 40\n",
    "\n",
    "test_data_dir = '/Cases/All cases/Test/'\n",
    "nb_test_samples = 40\n",
    "\n",
    "if Dataset == '60/6':\n",
    "  train_data_dir = '/Cases/60+6/Training/'\n",
    "  nb_train_samples = 66\n",
    "  test_data_dir = '/Cases/60+6/Test/'\n",
    "  nb_test_samples = 40\n",
    "  validation_data_dir = '/Cases/60+6/Validation/'\n",
    "  nb_validation_samples = 40\n",
    "elif Dataset == '33/33':\n",
    "  train_data_dir = '/Cases/33+33/Training/'\n",
    "  nb_train_samples = 66\n",
    "else:\n",
    "  train_data_dir = '/Cases/All cases/Training/'\n",
    "  nb_train_samples = 120\n",
    "\n",
    "ds_size = {\n",
    "    \"Train_Hematoma\": len(glob(train_data_dir + \"Hematoma/*\")),\n",
    "    \"Train_Normal\": len(glob(train_data_dir + \"Normal/*\")),\n",
    "    \"Val_Hematoma\": len(glob(validation_data_dir + \"Hematoma/*\")),\n",
    "    \"Val_Normal\": len(glob(validation_data_dir + \"Normal/*\")),\n",
    "    \"Test_Hematoma\": len(glob(test_data_dir + \"Hematoma/*\")),\n",
    "    \"Test_Normal\": len(glob(test_data_dir + \"Normal/*\")),\n",
    "}\n",
    "\n",
    "# For generator we need to give these two hyperparameters\n",
    "epochs = 40\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "# This is the augmentation configuration we will use for training\n",
    "dataaug = Augmentation\n",
    "\n",
    "if dataaug == \"off\":\n",
    "  print(\"Data Augmentation OFF\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255) # normalization\n",
    "elif dataaug == \"on\":\n",
    "  print(\"Data Augmentation ON\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255, # normalization\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      rotation_range=20,\n",
    "      fill_mode=\"constant\",\n",
    "      horizontal_flip=True)  \n",
    "else:\n",
    "  print(\"Data Augmentation Custom\")\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255, # normalization\n",
    "      width_shift_range=width_shift_range,\n",
    "      height_shift_range=height_shift_range,\n",
    "      shear_range=shear_range,\n",
    "      fill_mode=\"constant\",\n",
    "      zoom_range=zoom, \n",
    "      rotation_range=angle,\n",
    "      horizontal_flip=horizontal_flip)\n",
    "\n",
    "# This is the augmentation configuration we will use for validation:\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255) # normalization\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255) # normalization\n",
    "\n",
    "print(\"Training set:\")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "print(\"Validation set:\")\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "print(\"Test set:\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=nb_test_samples,\n",
    "    class_mode='binary', shuffle = False)\n",
    "\n",
    "clear_output()\n",
    "\n",
    "#Let's plot the class frequencies\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Traininig Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Train_Hematoma'], ds_size['Train_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Validation Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Val_Hematoma'], ds_size['Val_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + '\\r\\n          Test Set Distribution')\n",
    "plt.figure()\n",
    "plt.bar([0, 1], [ds_size['Test_Hematoma'], ds_size['Test_Normal']], color=['red', 'blue'])\n",
    "plt.xticks([0, 1], ('Hematoma', 'Normal'))\n",
    "plt.show()\n",
    "\n",
    "# Let's plot the first 4 generator outputs, defining the positive cases as Label = True and negatives as Label = False \n",
    "\n",
    "print ('\\033[1m' + '\\r\\nNow let\\'s see some examples\\r\\n')\n",
    "\n",
    "x,y = train_generator.next()\n",
    "\n",
    "labley = y==0\n",
    "#shape = x.shape\n",
    "#print (shape)\n",
    "#for i in range(0, 8):\n",
    "#  plt.subplot(240 + 1 + i).grid(False)\n",
    "#  plt.imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "#  plt.title(\"\\nLable:{}\".format(labley[i]))\n",
    "#  plt.axis('off')\n",
    "\n",
    "start_idx = 0\n",
    "fig, ax = plt.subplots(2,5, figsize=(15,8))\n",
    "for j in range(0,2): \n",
    "  for i in range(0,5):\n",
    "     ax[j][i].xaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].yaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].imshow(x[start_idx], cmap='gray')\n",
    "     ax[j][i].set_title(\"Index:{} \\nLabel:{}\".format(start_idx, labley[start_idx]))\n",
    "     start_idx +=1\n",
    "plt.show()\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZr5PnzuynjJ"
   },
   "source": [
    "<center> <img src=\"https://github.com/igorafaelms/rsna_handson/blob/master/transfer_learning.png?raw=true\"> </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi3uEzBZHr0w"
   },
   "outputs": [],
   "source": [
    "#@title Setting Neural Net {display-mode: \"form\"}\n",
    "\n",
    "transfer_learning = \"imagenet\" #@param [\"None\", \"imagenet\"]\n",
    "\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "# We can improve our results using transfer learning\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "if transfer_learning==\"None\":\n",
    "  base_model = VGG16(weights=None, include_top=False, input_shape=(img_width, img_height, 3))\n",
    "else:\n",
    "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "# Let's edit the last layers of VGG16 to use it in our solution\n",
    "\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "clear_output()\n",
    "from keras.models import Model\n",
    "clear_output()\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "clear_output()\n",
    "from keras import optimizers\n",
    "clear_output()\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Only for version 2\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# And a logistic layer\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "SIIM_Net= Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# We can try using a different optimizer as well\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "SIIM_Net.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "clear_output()\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpWTo4nSIPDy"
   },
   "outputs": [],
   "source": [
    "#@title Training and Validation {display-mode: \"form\"}\n",
    "epochs = 20 #@param {type:\"slider\", min:5, max:80, step:1}\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "# Time to train it\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Best_model.hdf5', monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "hist = SIIM_Net.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=nb_validation_samples // batch_size,\n",
    "            callbacks=[checkpointer])\n",
    "\n",
    "#Plotting the loss function\n",
    "\n",
    "plt.plot(hist.history['loss'], 'b-', label='train loss')\n",
    "plt.plot(hist.history['val_loss'], 'r-', label='val loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(hist.history['acc'], 'b-', label='train accuracy')\n",
    "plt.plot(hist.history['val_acc'], 'r-', label='val accuracy')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('\\033[1m' + \"Best Validation Accuracy: \" + str(hist.history['val_acc'][np.argmin(hist.history['val_loss'])]))\n",
    "print(\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5jVTnNKJfyj"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - Score Histogram per Class { display-mode: \"form\" }\n",
    "\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "from keras.models import load_model\n",
    "from tabulate import tabulate\n",
    "\n",
    "#Loading the best model\n",
    "\n",
    "best_model = load_model('Best_model.hdf5')\n",
    "\n",
    "X, Y = test_generator.next() # Get the X (images) and Y (labels) of the test set\n",
    "\n",
    "labels_pred = best_model.predict(X) #predict the output from X\n",
    "\n",
    "labels_test = Y\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "Y_neg = (1-labels_pred[labels_test == 1])\n",
    "\n",
    "Y_pos = (1-labels_pred[labels_test == 0])\n",
    "headers = [\"Normal\", \"Hematoma\"]\n",
    "print(tabulate([[Y_neg,Y_pos]],headers,tablefmt=\"orgtbl\"))\n",
    "\n",
    "bins = np.linspace(0, 1, 100)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(Y_neg, bins, alpha=0.4, label='Normal')\n",
    "plt.hist(Y_pos, bins, alpha=0.4, label='Hematoma')\n",
    "plt.legend(loc='upper center')\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJNi_Gts8dty"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - 2 x 2 table { display-mode: \"form\" }\n",
    "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "# This code will be hidden when the notebook is loaded.\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "#Loading the best model\n",
    "\n",
    "best_model = load_model('Best_model.hdf5')\n",
    "\n",
    "\n",
    "# Defining a function to plot a confusion matrix.\n",
    "\n",
    "# from https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = '2x2 table'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "        #print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='Ground-truth label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[1]):\n",
    "        for j in range(cm.shape[0]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "X, Y = test_generator.next() # Get the X (images) and Y (labels) of the test set\n",
    "\n",
    "labels_pred = best_model.predict(X) #predict the output from X\n",
    "\n",
    "#labels_pred = labels_pred > labels_pred.mean() #predictions greater than mean are set to 1, those lesser than or equal to mean are set to 0.\n",
    "\n",
    "labels_pred = labels_pred >= threshold\n",
    "\n",
    "labels_test = Y\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(labels_test, labels_pred.astype('int'), classes=['Hematoma','Normal'], normalize=False,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "accuracy = metrics.accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "#print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-z04WjMXWLE"
   },
   "outputs": [],
   "source": [
    "#@title Algorithm Performance (test set) - ROC Curve {display-mode: \"form\"}\n",
    "\n",
    "threshold = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
    "\n",
    "#Plotting the ROC curve with the AUC\n",
    "\n",
    "labels_pred = best_model.predict(X) # predict again to get the original sigmoid output [0,1]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(labels_test, labels_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.plot(fpr[np.argmin(np.abs(thresholds-threshold))],tpr[np.argmin(np.abs(thresholds-threshold))], 'o', color='red')\n",
    "\n",
    "plt.xlim([-0.01, 1.0])\n",
    "plt.ylim([0.0, 1.01])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "#labels_pred = labels_pred > labels_pred.mean() #predictions greater than mean are set to 1, those lesser than or equal to mean are set to 0.\n",
    "\n",
    "labels_pred = labels_pred >= threshold\n",
    "\n",
    "f1_score = metrics.f1_score(labels_test, labels_pred, labels=None, pos_label=0, average='binary', sample_weight=None)\n",
    "\n",
    "accuracy = metrics.accuracy_score(labels_test, labels_pred)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy))\n",
    "\n",
    "print(\"F1 Score: \" + str(f1_score))\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7v2NUvMT7aib"
   },
   "outputs": [],
   "source": [
    "#@title Test Evaluation - Prediction on sampled images {display-mode: \"form\"}\n",
    "\n",
    "\n",
    "# Finally, we can use the test set for predictions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test_data_dir = '/Cases/All cases/Test/' # location of test dataset\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "         rescale=1./255)       # normalize pixel values to [0,1]\n",
    "\n",
    "# Preparing test set images for prediction\n",
    "\n",
    "itr = test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=40,\n",
    "    shuffle='False',\n",
    "    class_mode='binary')\n",
    "batch_x, batch_y = itr.next()\n",
    "\n",
    "print('Test group accuracy: ', best_model.evaluate(batch_x, batch_y, verbose=0)[1])\n",
    "\n",
    "\n",
    "\n",
    "from random import randrange\n",
    "\n",
    "prediction1 = np.round(best_model.predict(batch_x, verbose=1))==0\n",
    "\n",
    "\n",
    "start_idx = randrange(batch_x.shape[0]-10) \n",
    "fig, ax = plt.subplots(2,5, figsize=(15,8))\n",
    "for j in range(0,2): \n",
    "  for i in range(0,5):\n",
    "     ax[j][i].xaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].yaxis.set_major_locator(plt.NullLocator())\n",
    "     ax[j][i].imshow(batch_x[start_idx], cmap='gray')\n",
    "     ax[j][i].set_title(\"Index:{} \\nPrediction:{}\".format(start_idx, 'Hematoma' if prediction1[start_idx][0] else 'Normal'))\n",
    "     start_idx +=1\n",
    "plt.show()\n",
    "\n",
    "print ('\\033[1m' + 'Ready for next step!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU3kUp6ccpVV"
   },
   "outputs": [],
   "source": [
    "#@title Visualization - Saliency Maps {display-mode: \"form\"}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing visualization tools\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from keras.layers import Input\n",
    "from keras import activations\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import initializers\n",
    "from keras.models import Sequential, Model\n",
    "from vis.visualization import visualize_activation,visualize_saliency,overlay,visualize_cam\n",
    "from vis.utils import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import imagenet_utils\n",
    "import numpy as np\n",
    "\n",
    "layer_idx = utils.find_layer_idx(best_model, 'block5_conv3')\n",
    "print(\"Remove Activation from Last Layer\")\n",
    "# Swap softmax with linear\n",
    "best_model.layers[layer_idx].activation = activations.linear\n",
    "print(\"Done. Now Applying changes to the model ...\")\n",
    "activation2_model = utils.apply_modifications(best_model)\n",
    "\n",
    "#print(activation_model.summary())\n",
    "#im_files=[\"/All cases/Test/Hematoma/Test hematoma (1).png\",\"/All cases/Test/Normal/Test_normal (1).png\"]\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "import os\n",
    "\n",
    "dir_name='/Cases/All cases/Test/'\n",
    "im_files = test_generator.filenames\n",
    "for im_file in im_files[3:6]:\n",
    "    img1 = image.load_img(dir_name + im_file,target_size=(150,150))\n",
    "    img1 = image.img_to_array(img1)\n",
    "    img1 = np.expand_dims(img1, axis=0)\n",
    "    img1 = preprocess_input(img1)\n",
    "    layer_idx = utils.find_layer_idx(activation2_model, 'block5_conv3')\n",
    "    heatmap = visualize_cam(activation2_model, layer_idx, filter_indices=range(activation2_model.layers[layer_idx].filters), seed_input=img1[0,:,:,:])\n",
    "    img_init=utils.load_img(dir_name + im_file,target_size=(150,150))\n",
    "    img_init = img_init[:,:,:3]\n",
    "    plt.figure(figsize=(10,10))\n",
    "    ax1 = plt.subplot(1,3,1)\n",
    "    ax1.grid(False)\n",
    "    plt.imshow(img_init, cmap='gray')\n",
    "    ax2 = plt.subplot(1,3,2)\n",
    "    ax2.grid(False)\n",
    "    plt.imshow(heatmap)\n",
    "    ax3 = plt.subplot(1,3,3)\n",
    "    ax3.grid(False)\n",
    "    plt.imshow(overlay(img_init, heatmap))\n",
    "    plt.show()\n",
    "    \n",
    "#print ('\\n' + '\\033[1m' + 'Congratulations, you have completed the assignment!')\n",
    "\n",
    "#from IPython.display import HTML\n",
    "#HTML('<img src=\"https://media.giphy.com/media/cub3pntkz8muQ/giphy.gif\">')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "RSNA for Non-Coders w comments.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
